----
### 前言
```
整理并码字不易，本文章请注意保密！谢谢！
```
大厂大佬往往以连环炮的形式，将一个话题追问到低。感受一下：
- 大佬：讲讲HashMap的底层原理？hash冲突是怎么解决的？
小A：HashMap是一个用于存储Key-Value键值对的集合。是一个主干为数组table，table的每一个元素是一个存储这些键值对（Entry）的链表。利用hash函数和table长度计算数组下标index。put操作时，若table[index]为null，则形成一个链表赋值给table[index]。否则意味着hash冲突，采用头插法插入到table[index]对应的链表中。
get操作时：若table[index]对应的链表中含有多个entry，则顺着链表通过equals方法一个个向下查找，找到符合的entry。
- 大佬：HashMap默认初始化长度是多少？为什么长度一定是2的幂？如何将key映射到HashMap数组的对应位置的？
小A：默认初始化长度是16，且每次自动扩展时的长度必须为2的幂。考虑到hash函数很重要，要保证尽量均匀的分布在数组的各个单元格中。通过求key的HashCode值解决了均匀的问题，但该值可能会很大超出了数组下标的最大值。若再通过取模运算的方式：index=HashCode(Key)%length，虽然简单但效率不高。HashMap为了高效采用了位运算：index=HashCode(Key)&(Length-1)。但这样做，要保证Length必须为2的幂，length-1的值所有二进制位才全为1。
这种一旦二进制位出现了0，任何数与0求位与都是0，将导致index有些结果根本不出现(如0011)，有些结果出现的概率会更大。
- 大佬：在Java8中，HashMap的结构有什么样的优化？
小A：jdk8中，当链表上结点数量>8时会转为红黑树。加快了查找速度。
- 大佬：HashMap与HashTable的区别？
小A：Hashtable每个方法都加了sychronized，是线程安全的，不接受null的key。而HashMap则非线程安全，相对而言HashMap性能会高一些。HashMap以null作为key时，都放在table[0]的位置。
- 大佬：高并发下HashMap会出现什么问题？
小A：为了减少了Key映射位置发生冲突的几率，当插入新元素时，HashMap发现已经超过了一定饱和度时会发生扩容（数组中非null单元格个数>=数组总长度*负载因子）。重新创建一个2倍长度的table，将每个entry重新计算index放到新的table中。两个线程同时rehash时容易造成循环链表，让下一次读操作出现死循环。
- 大佬：除了HashTable，还有什么样的map实现类可以保证线程安全呢？结构是什么样子的？
小A：Hashtable或Collections.synchronizedMap无论是读操作还是写操作，都会给整个集合加锁，导致同一时间的其它操作为之阻塞，而ConcurrentHashMap能兼顾线程安全和运行效率。ConcurrentHashMap是在一个总的哈希表下面有若干个子哈希表的一个二级哈希表，每个子哈希表称为segment，每一次读写操作都需要进行两次hash运算（首先定位到Segment，之后定位到Segment内的具体数组下标）。
- 大佬：在并发场景下，ConcurrentHashMap是怎么保证线程安全的？又是怎么实现高性能读写的呢？
小A：segment锁分段技术。每个segment各自持有一把锁，降低了锁的粒度。写线程才需要锁定而读线程不需要，put方法两次hash运算之间获得重入锁。求size方法：遍历每一个Segment，把Segment的元素数量和修改次数都累加起来，如果总修改次数大于上次修改的总次数，说明统计过程修改过，则重新计算。否则说明没有修改，统计结束。若N次都没有统计好，这对每一个Segment加锁并重新统计，这种先用乐观锁再用悲观锁的方式。
- 大佬：有没有有顺序的Map实现类？是如何保证它的顺序的？
小A：TreeMap：能够把它保存的记录根据键排序。基于红黑二叉树实现，key不允许null。元素需实现Comparable(内比较器)接口或Comparator接口。LinkedHashMap：保存了记录的插入顺序。内部依赖哈希表和链表列实现，由hash保证键的唯一性，由LinkedList保证有序性。key允许为null。
- 大佬：TreeMap是线程安全的么？高并发程序，有没有更好的实现方式？
小A：非也！使用ConcurrentSkipListMap替代TreeMap。ConcurrentSkipListMap提供了一种线程安全的并发访问的排序映射表。内部是SkipList（跳跃表）结构实现，时间复杂度为O(log(n))。线程安全的原理是利用底层的插入、删除的CAS原子性操作。

----
### core java
```
常用的集合类和并发编程相关的往往是常考点。
```
101.hashCode的作用？hashCode相等的两个对象一定相等吗？equals呢？反过来相等吗？
①hashCode主要用于查找的快捷性，用在散列存储结构中确定对象的存放位置。如HashSet中要保证每个对象是唯一的，在add(obj)时不需要与集合中所有对象都比较一遍，而是先通过obj的hashCode快速定位位于hash表的哪个桶中，再通过equals()只需要比较该链上已有对象即可，大大减少了比较次数（hashCode不同的对象一定不同）。②都不一定，hashCode()和equals()都是可以随便重写的。但JDK规定，equals相等hashCode必须相等，反之就不一定。hashCode默认是对象在内存的存储地址转换成一个整数来实现的，equals默认实现是用==比较。

102.说说你了解的同步类容器和并发类容器？java.util.Collection与java.util.Collections的区别？
①同步类容器：Vector、HashTable、Collections.synchronizedXXX。并发类容器：ConcurrentHashMap、ConcurrentSkipListHashMap、CopyOnWriteArrayList（使用了一种叫写时复制的方法，当有新元素添加到CopyOnWriteArrayList时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组，适合读多写少的场景）。④Collections是工具类，提供了很多有关集合操作的静态方法；Collection是集合接口，提供了集合对象基本操作的通用接口。

Collection
 ├ List
 │  ├ ArrayList 非线程安全，底层是数组。扩容方式：初始化长度为10，长度不足时会自动扩容，扩容公式：当前容量长度*1.5+1。
 │  ├ LinkedList 非线程安全，底层是链表。
 │  └ Vector 线程安全，
 ├ Set
 │  ├ TreeSet
 |  └ HashSet
Map
 ├ Hashtable 线程安全
 ├ HashMap   非线程安全，
 |  └ LinkedHashMap：HashMap和双向链表合二为一，通过维护一个额外的双向链表保证了迭代顺序。该迭代顺序可以是插入顺序，也可以是访问顺序。
 └ WeakHashMap  非线程安全

103.线程池都有哪些参数？线程池的实现原理？介绍一下Executors提供的四种线程池？线程数设置多少比较合理？什么情景下使用多线程？突然断电了，线程池会怎么样？
①参数：ThreadPoolExecutor(核心池数量,最大线程数,缓存时间,时间单位,阻塞队列,队列满时处理策略)
阻塞队列：SynchronousQueue（直接提交策略）、LinkedBlockingQueue（无界队列）、ArrayListBlockingQueue（有界队列）。
拒绝策略：丢弃任务并抛异常、丢弃任务但不抛异常、丢弃队列最前面的任务、由调用线程处理该任务、自定义。
②假设初始化一个线程池，核心线程数是5，最大线程数是10。初始化时里面没有线程，当来了一个任务时，在线程池中初始化一个线程，直接到第6个任务来，这时把第6个任务放到阻塞队列中，如果5个线程中有空闲了，就会从阻塞队列中获取第6个任务。若5个线程都在running，那任务就先保存在阻塞队列中。如果队列满了，这时会新建一个线程执行不能保存到阻塞队列的任务，直到线程数达到10个。如果线程数也到达10个，阻塞队列也满了，则通过reject函数处理这些任务了。若运行一段时间阻塞队列中的任务执行完了，超过核心线程数的线程会在空闲一段时间内自动回收。
③SingleThreadExecutor：单线程（thread异常结束时，会new一个thread补充）；FixedThreadPool：固定大小的线程池；CachedThreadPool：大小可伸缩线程池，执行结束后缓存60s，若不被调则移除线程。ScheduledThreadPool:具有时间调度特性的线程池，用DeplayedWorkQueue实现的。
④一般根据任务类型来设置线程数（假设N为CPU核数）：1）若为计算密集型任务，参考值为N+1；2）若为IO密集型任务，参考值为2N+1；3）最佳线程数=((线程等待时间+线程消耗CPU时间)/线程消耗CPU时间)*N。
⑤1）多任务同时执行加快处理速度：如批量给满足条件的用户发送短信；2）异步执行：UI线程和后台Work线程分开，这样不会造成UI假死。总结：短期模型相同的任务使用线程池，长期任务使用独立线程。
⑥对正在处理的任务做事务管理，对阻塞队列中的任务持久化处理。当断电后，通过回溯日志的方式来撤销正在处理的已经执行成功的操作，重新执行整个阻塞队列。

104.java对象在内存中的结构划分？简述synchronized Object Monitor机制？
①HotSpot虚拟机中，对象在内存中存储布局分为3块区域：对象头(Mark Word+Class对象地址)、变量数据和对齐填充。
估算对象大小(32位HotSpot)：class A{int i;byte b;String str;}计算：对象A一共占用了4(Mark Word)+4(类型指针)+4(i)+1(b)+4(str)=17字节，按8字节对齐原则，对象大小也就是24字节。
HotSpot虚拟机底层中有这样一个类，每一个java对象都存在着一个该类的实例monitor，通过monitor的这些变量用来管理访问该java对象的多线程。
- synchronized代码块使用了monitorenter和monitorexit指令实现。
- synchronized方法中依靠方法修饰符上的ACC_SYNCHRONIZED实现。
当多个线程同时请求某个对象synchronized方法或代码块时，本质上都是这些线程对该对象竞争owner的过程。同一时刻只会有一个线程成为该对象的'主人'，成功的线程将monitor中的owner变量设置为当前线程，count加1，执行被synchronized修饰的代码。其它失败的线程会被阻塞（BLOCKED状态），并放入到EntryList队列中。如果运行的线程调用对象的wait()后，则将owner变量恢复为null，count减1，同时该线程进入WaitSet集合中等待被唤醒，当调用对象的notify()或notifyall()后，wait线程就被添加到EntryList队列中。若当前线程执行完毕也恢复owner和count变量，以便EntryList中其它线程继续竞争上岗（synchronized是不公平竞争锁）。
Mark Word用2bit标志位来显示锁类型，synchronized的对象锁就是这里标志位为10时的monitor对象。

105.synchronized和Lock接口的区别？jdk1.6以后对synchronized的优化？分别什么情况下是对象锁和是全局锁？
①synchronized：JVM执行的，悲观锁，抛异常，会自动释放锁；Lock：java写的，CAS实现，必须在finally释放锁。
②在实现上分为了偏向锁、轻量级锁、自旋锁和重量级锁。这几个锁的状态会随着竞争情况逐渐升级：无锁->偏向锁->轻量级->重量级，但不能降级。
偏向锁：锁会偏向第一个获取它的线程，短时间内执行不会被其他的线程获取，jdk1.6默认开启的；
轻量级锁：在没有多线程竞争的情况下，减少重量级锁使用操作系统互斥量产生性能损耗，在当前线程的栈帧中生成一个锁记录，锁记录只是对象头的一个拷贝，并把对象头的标志位改为00；
自旋锁：没有获得锁的线程会被挂起阻塞，而挂起和恢复线程的操作都需要cpu从用户态转为内核态，频繁的挂起和恢复对cpu来说负荷很重。monitor并不把未获得锁的线程放入排队队列，而是去执行一次循环，循环结束后若发现锁已释放直接进行竞争上岗，如果竞争不到继续自旋循环，默认开启。缺点是该线程会一直占用处理器。
③synchronized修饰在非静态方法上代表对象锁，静态方法为类锁，因为调用静态方法时对象不一定创建。

106.谈谈ThreadLocal的作用？底层如何实现的？会不会导致内存泄露？
①如项目中filter获取到了用户登录的uid，该请求后续service层和dao层都需要用到这个uid。为了减少多个方法之间变量的传递，可以使用ThreadLocal让该变量在线程的生命周期内起作用。②每一个线程都有一个Map（该Map来自于Thread类中定义的ThreadLocalMap），该Map的key为我们定义的ThreadLocal对象本身，value为我们要存储的变量值（如uid）。这样保证了多线程间该变量值的隔离，线程消亡时，对应的Map自动被销毁。注意：ThreadLocal本身不存储值，只是作为一个key让线程从ThreadLocalMap获取value。③内存泄露：ThreadLocalMap使用了弱引用，不过弱引用只是针对key，当threadLocal引用设置为null后，threadLocal实例将会被gc回收，即key被回收。但是value却不能回收，因为存在一条从当前线程currentThread连接过来的强引用，只有当前线程结束之后，强引用才会断开，value将被GC回收。

107.谈谈volatile的作用？实现原理以及使用场景。
①volatile只能保证多线程三大特性中的可见性和有序性。1）可见性：每个线程都有一个自己的本地内存，对于共享变量，线程每次读取和写入的都是共享变量在本地内存中的副本，然后在某个时间点将本地内存和主内存的值进行同步。而当修改volatile修饰的变量后，强制把对变量的修改同步到主内存。而其它线程在读取自己的本地内存中的值的时候，发现是valotile修饰的且已经被修改了，会把自己本地内存中的值置为无效，然后从主内存中读取。2）有序性：在执行程序时，为了提高性能，处理器和编译器常常会对指令进行重排序，这种重排序一般只能保证单线程下执行结果不被改变。当被volatile修饰的变量后，将会禁止重排序。②代码层面实现：通过内存屏障来实现的。所谓的内存屏障，是在某些指令中插入屏障指令。虚拟机读取到这些屏障指令时主动将本地内存的变量值刷新到内存，或直接从主内存中读取变量的值。通过屏障指令会禁止屏障前的操作命令和屏障后的命令进行重排序。系统层面实现：在多处理器下，保证各个处理器的缓存是一致的，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态。③1:多线程间状态标识；2:单例模式中双重检查锁的写法；3:定期观察成员变量状态的方法。

108.简述happen-before规则？举两个例子。
①编译器或运行时为了效率可以在允许的时候对指令进行重排序，这就引起了线程间可见性问题。通过制定一些通用规则规定某些场景某个线程修改的变量何时对另一个线程可见。happen-before不是描述实际操作的先后顺序，而是用来描述可见性的一种规则。②如线程1解锁了a，接着线程2锁定了a，那么线程1解锁a之前的所有写操作都对线程2可见；如线程1写入了volatile变量v，接着线程2读取了v，那么线程1写入v对线程2可见。

109.请至少用四种写法写出单例模式的实现？不加volatile时DCL失效原因？
① 1）饿汉模式：类加载时就创建对象。2）懒汉模式：synchronized修饰在方法上。3）双重检查锁（DCL）：双重判断+同步+volatile。4）枚举。5）静态内部类：
private static class InnerSingletion {
	private static Singleton4 single = new Singleton4();
} // 推荐！类级内部类只有在第一次被使用的时候才被会装载。
②在最内层，instance = new Singleton()。这句赋值语句，其实是分三步来操作的：
memory = allocate(); //a.为instance分配内存
ctorInstance(memory); //b.初始化对象
instance = memory; //c.设置instance指向刚分配的内存地址
jvm会对上述步骤b和c可能会进行重排序，c先执行，但是对象却没初始化，这时候其他线程判断的时候，发现是非null，但是使用的时候，却没有具体实例，导致报错。需要使用volatile修饰instance，避免该问题。

110.什么是序列化以及用途？java实现序列化注意的点？
①序列化：把Java对象转换为字节序列的过程；反序列化：把字节序列恢复为Java对象的过程。②用途：1.将对象的字节永久地保存到磁盘上；2.在网络上传送对象的字节序列（如RMI）。③ 1）java实现序列化：将序列化的类实现Serializable接口，使用ObjectOutputStream的writeObject()进行输出。2）被static、transient修饰的字段不会被序列化。在被反序列化后，transient变量的值被设为初始值，如int型的是0，对象型的是null。3）序列化时只保存对象的状态，而不管对象的方法。如果对象的成员变量是一个对象，那么这个对象的成员也会被保存。

111.讲一下java线程状态之间的变换过程？与线程相关的几个方法的比较？为什么wait()一般建议要放在循环中？
①new---start()->runnable--分配cpu-->running-->waiting-->blocked-->dead
②Thread.sleep(millis)：当前线程调用此方法，当前线程进入阻塞状态，但不释放对象锁，时间到后自动进入可运行状态;
Thread.yield()：当前线程调用此方法，当前线程放弃获取cpu时间片，由运行状态变为可运行状态;
t.join()/t.join(millis)：当前线程调用其它线程t的join方法，当前线程阻塞，但不释放对象锁，直到线程t执行完毕或者millis时间到，当前线程进入可运行状态。
obj.wait()/obj.wait(millis)：当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者millis时间到自动唤醒。
notify()/notifyAll()：随机唤醒一个/所有等待该对象锁的线程，进入就绪队列等待CPU的调度；注意唤醒的是notify之前wait的线程，对于notify之后的wait线程是没有效果的，notify不释放锁（使用CountDownLatch可以解决notify不释放锁、不实时的问题）。
③如果采用if判断，当线程从wait中唤醒时，那么将直接执行处理其他业务逻辑的代码，但这时可能出现另外一种可能，条件谓词已经不满足处理业务逻辑的条件了，从而出现错误的结果，于是有必要进行再一次判断。

112.有三个线程T1，T2，T3，怎么确保它们按顺序执行？如何唤醒一个阻塞的线程？
①T3先执行，在T3的run中，调用t2.join，让t2执行完成后再执行t3。在T2的run中，调用t1.join，让t1执行完成后再让T2执行。
②如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它；如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的。

113.什么是线程死锁？死锁如何产生？如何避免线程死锁？
①指由于两个或者多个线程互相持有对方所需要的资源，导致这些线程处于等待状态，无法继续执行下去。②假设有资源A和资源B，线程t1和线程t2，每个资源同一时刻只能被一个线程持有。某个时刻，t1持有了资源A，t2持有了资源B，t1竞争资源B，t2竞争资源A，而t1和t2又对已持有的资源不释放，形成死循环导致死锁。③1）加锁顺序：当多个线程需要相同的一些锁，保持按照相同的顺序加锁；2）加锁时限：加上一个超时时间，如果一个线程没有在给定的时间内成功获得所需要的锁，则释放所有已获得的锁；3）死锁检查：每当一个线程获得了锁，在线程和锁相关的数据结构中将其记下来，检查到死锁的时候回退某个线程。

114.简单谈谈你对CAS的认识和理解？
unsafe类的compareAndSwap方法，乐观锁的一种实现方式，CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个操作是一个原子操作。
问题：ABA，循环时间长开销大，只能保证一个共享变量的原子操作。解决ABA问题的方法：AtomicStampedReference，通过控制变量值的版本来保证CAS的正确性。

115.AQS（抽象队列同步器）的实现原理
ReentrantLock/Semaphore/CountDownLatch都是基于AQS实现的。
原理：维护了volatile int state（代表共享资源）和FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）;
AQS内部会保存一个状态变量state，通过CAS修改该变量的值，修改成功的线程表示获取到该锁，没有修改成功，或者发现状态state已经是加锁状态，则通过一个Waiter对象封装线程，添加到等待队列中，并挂起等待被唤醒。
两种资源共享方式：独占/共享（允许多个线程同时获取锁）
CAS来对state状态进行操作，ReentrantLock默认nonfair，也可以fair（排队获取锁），lock不成功进入等待队列。ReadWriteLock同时多线程读，单线程写。

116.如果想实现所有的线程一起等待某个事件的发生，当某个事件发生时，所有线程一起开始往下执行的话，有什么好的办法吗？
用栅栏CyclicBarrier。

JUC包下的tools：
● CountDownLatch（闭锁）：允许一个或多个线程等待一系列指定操作的完成。等待事件。
● CyclicBarrier（栅栏）：允许一组线程互相等待，直到到达某个公共屏障点，可以重复使用。等待其它线程。
● Semaphore（信号量）：限制同时访问某个资源的线程数。
● Exchanger（交换数据）：表示一种两个线程可以进行互相交互对象的汇合点。

JUC包下的locks：
Lock
│ └ ReentrantLock（可重入的互斥锁）：同一个时间点只能被一个线程锁持有，可以被单个线程多次获取。分公平锁和非公平锁
Condition：条件变量，通过await()和signal()线程间通信。与Lock结合使用。
ReadWriteLock（读写锁）：读读不互斥，读写互斥，写写互斥。
│ └ ReentrantReadWriteLock
LockSupport

JUC包下的collections：
Queue
│ ├ ConcurrentLinkedQueue：无阻塞队列
│ ├ BlockingQueue
│ └ Deque
CopyOnWriteArrayList
CopyONWriteArraySet
ConcurrentSkipListSet
ConccuentMap
  ├ ConcurrentHashMap
  └ ConcurrentSkipListSet

JUC包下的executor：
Future
│ ├ RunnableFuture
│ │ └ FutureTask
│ └ ScheduledFuture
Callable
Executor
│ └ ExecutorService
│ │ ├ ScheduledThreadPoolExecutor
│ │ └ ThreadPoolExecutor
RejectedExecutionHandler：ThreadPoolExecutor.DiscardPolicy、ThreadPoolExecutor.DiscardOldestPolicy、ThreadPoolExecutor.CallerRunsPolicy、ThreadPoolExecutor.AbortPolicy。

117.说说你了解的一个线程安全队列？
BlockingQueue：阻塞队列。含offer(e)、offer(e,time)、add(e)、put(e)、peek(e)、poll(e)、poll(e,time)、take(e)等方法。
├ ArrayBlockingQueue：没有采用读写分离、add和poll不能同时进行
├ LinkedBlockingQueue：读写分离、支持写入和读取并发操作
├ SynchronousQueue：没有任何容量
├ PriorityBlockingQueue：带优先级的阻塞队列
└ DelayQueue：带有延迟功能的阻塞队列
ConcurrentLinkedQueue：无阻塞队列

118.Fork/Join框架原理
Java7提供了的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。采用“工作窃取模式”（空闲的线程从其它线程的任务队列后面窃取一个任务来处理）。

119.BIO、NIO、AIO的区别是什么？
BIO：1）一个连接一个线程：客户端有连接请求时服务器端就需要启动一个线程进行处理（一客户端一线程）。如果这个连接没有数据传输时会造成不必要的开销，且当客户端很多时，线程的分配需要一定的内存空间且线程上下文切换也是负担。2）数据是以字节为单位进行传输的。3）同步阻塞：当一个线程发起IO操作后，直到有数据才可以被读或写，在此期间该线程不能再干其它事情了。
NIO：1）一个请求一个线程：客户端发送的连接请求都会注册到多路复用器（多个网络连接复用在同一个线程）上，多路复用器轮询到连接有IO请求时才启动一个线程进行处理。2）数据传输基于块。3）同步非阻塞：当一个线程发起IO操作后可返回做其它事情，但还要时不时的询问IO操作是否就绪。
三个重要的类Selecotr/Channel/Buffer：每个客户端的socket连接对应一个Channel（即可读又可写的双向通道），每一个Channel对应一个Buffer（就是一个内存，底层用数组实现的），Channel是用来传输数据，而Buffer才是读写数据的载体。多个Channel在Selector上进行注册，Selector对应一个单独的线程，该线程不断的对这些Channel轮询，找出已经准备好的IO进行处理，没有准备好的不处理也不会产生阻塞。
AIO：1）一个有效请求一个线程。2）异步：当一个线程发起IO操作后，不需要等待IO操作完成，等IO操作完成以后会通知应用程序。

120.Object类的finalize方法的实现原理？如何验证finalize方法是否被执行了？
①新建一个对象时，在JVM中会判断该对象对应的类是否重写了finalize方法，且finalize方法体不为空，则把该对象封装成Finalizer对象，并添加到Finalizer链表。Finalizer类中会初始化一个FinalizerThread类型的线程，负责从一个引用队列中获取Finalizer对象，并执行该Finalizer对象的runFinalizer方法，最终会执行原始对象的finalize方法。②初始化一个大数组，可以明显看出gc之后是否被回收，然后执行System.gc()，在finalize方法中输出信息。

----
### JVM
201.请介绍一下JVM内存模型中分为哪几部分，分别都存储哪些数据？哪些是线程共享的区域？
虚拟机栈+本地方法栈：每个方法执行时创建一个栈帧（保存方法的局部变量、操作数和返回值等），栈的大小决定了方法的调用的可达深度，大于则抛stackOverflowError，没有内存支持动态扩展了则抛OutofMemoryError。线程私有的区域。
堆：分新生代（eden区、survivor0区、survivor1区）和老年代，存储java对象的地方。线程共享的区域。
程序计数器：线程记录下一条要运行的指令，方便再次被cpu调度。线程私有的区域。
方法区（永久代）：类加载的元数据信息（常量、静态变量和编译后的代码），jdk8之后使用了本地内存中的元数据区取代了永久代。线程共享的区域。
本地内存：本区域不在虚拟机中，分‘元数据区’和‘直接内存’。jdk1.4引入了NIO，NIO使用Native函数库直接分配堆外内存。jdk8引入了元数据区。线程共享的区域。

202.内存溢出和内存泄露的区别？分别的原因及解决方案？
①内存溢出：指内存不够用了。内存泄露：一个对象分配内存之后，在使用结束时未及时释放，导致一直占用内存，没有及时清理。
②溢出原因：1）内存中加载的数据量过于庞大，如一次从数据库取出过多数据；2）代码中存在死循环或循环产生过多重复的对象实体；3）使用的第三方软件中的BUG；4）启动参数内存值设定的过小。泄露原因：使用完的对象未及时设置为null，使得这些对象不能被GC回收。③溢出解决方案：1）修改JVM启动参数（-Xms，-Xmx），直接增加内存。2）检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。3）对代码进行走查和分析，找出可能发生溢出的位置。如检查数据库查询记录是否过多、是否存在死循环或者递归调用。泄露解决方案：1）检查List、Map等集合对象是否使用完后，还存在这些对象的引用；2）对象超出了活动作用域，没有及时设置为null或者关闭。

203.什么是Minor GC、Major GC和Full GC？Young GC的大概过程？什么样的对象会晋升到老年代？
①Java内存分配和回收是：分代分配，分代回收。新生代（eden+两个survivor，默认比例为8:1:1）触发Minor GC，老年代、持久代、System.gc和GC担保失败会触发Major GC。Major GC会对老年代进行GC，Full GC会对整个Heap进行GC。
②Minor GC又叫Young GC。绝大部分刚创建的对象会被分配在Eden区，而大多数对象很快就会消亡。当Eden区满的时候，执行Minor GC。先找出根对象，如Java栈中引用的对象、静态变量引用的对象和常量池中引用的对象等，把这些对象标记成活跃对象（可达性分析），接着遍历这些活跃对象中引用的对象，找出在eden区有引用关系的对象并标记，把这些标记的对象复制到to区（survivor0和survivor1总会有一个是空白的，空白的叫to区，另一个叫from区），在复制过程还要判断活跃对象的gc年龄（每熬过一次YGC依然没有被回收，年龄就增加一岁）是否已经达到阈值（默认15岁，可通过-XX:MaxTenuringThreshold进行控制），如果已经达到阈值，就直接晋升到老年代。清理掉eden区和from区非标记的对象。YGC结束之后把from和to的引用互换。③若进行YGC时发现，存活的对象在to区中存不下，那么把存活的对象存入老年代。若新创建的对象大于阙值（默认3M，可通过-XX:PretenureSizeThreshold进行控制），直接存入老年代。还有一种情况，如果在from空间中，相同年龄所有对象的大小总和大于from和to空间总和的一半，那么≥该年龄的对象就会被移动到老年代，而不用等到15岁。

204.垃圾回收算法都有哪些？你了解的垃圾收集器？CMS收集器回收的过程？
①1）标记清除算法：将没有标记的垃圾对象进行清除，但回收后的空间不连续；2）复制算法(新生代)：内存分两块，每次使用一块；3）标记整理算法(老年代)：标记后不复制，而是将对象压缩到内存的一端，然后清理界外对象。②1）Serial(复制)/Serial Old(标记整理)：单线程收集，需暂停所有用户线程；2）ParNew(复制)：多个线程进行收集；3）Parallel Scavenge(复制)/Parallel Old(标记整理)：并行收集；4）CMS(标记清除)：最小回收时间停顿并发收集器；5）G1：可预测停顿时间。G1将内存划分为一个个相等大小的内存分区，回收时则以分区为单位进行回收，存活的对象复制到另一个空闲分区中。G1虽然也是分代收集器，但整个内存分区不存在物理上的年轻代与老年代的区别，每个分区都可能随G1的运行在不同代之间前后切换。可以通过设置预期停顿时间来控制垃圾收集时间避免应用雪崩现象。③CMS回收过程：初始标记、并发标记、重新标记、并发清除；初始标记、重新标记这两步骤仍然需要stop the world，初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长点，但远比并发标记的时间短。

205.你做过哪些JVM方面的优化？使用的什么方法？达到了什么效果？线上jvm如何配置的？
eg：秒杀项目上线的时候，发现YGC特别的频繁，通过调整新生代的大小（线上环境的虚拟机参数是默认的），同时检查业务逻辑代码。
-Xms2048m -Xmx12G(JVM最大可用内存，占总内存的一半) -XX:PermSize=256m -XX:MaxPermSize=512m -XX:NewRatio(年轻代和年老代的比值，官网推荐新生代占整个堆的3/8)=3 -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=7 -XX:GCTimeRatio(垃圾回收时间与非垃圾回收时间的比值)=19 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC

206.如何处理线上频繁发生Full GC？CPU使用率过高怎么办？说出你的思路和处理方法？
①使用jps命令找到要排查应用的pid（如14063），通过jstat -gcutil 14063 2000 10查看使用空间占总空间的百分比，查看各代gc次数和前后大小变化。通过jmap -histo[:live] pid查看堆内存中对象数量和大小。加live后比不加live少很多大对象证明是大量的请求进入分配内存而处理不过来导致频繁full gc，反之则存在不当的引用导致内存泄露。JVM参数中加入-XX:+DisableExplicitGC来禁止System.gc()试一下。
②通过top命令先找到占用大量cpu资源的进程的pid(shift+p命令按cpu使用率进行排序)，如pid为211。top -Hp 211找到最耗cpu的线程，如tid为1211，将tid转换为16进制如为52f1。使用jstack pid |grep tid -A 30打印线程栈信息(可查看类的行号)，找到cpu过高的原因。如果这些线程是gc线程，可确定内存不足或者泄露导致的。
> 类似还有内存泄露、线程卡死、jvm崩溃等问题，一般都是折腾jdk的bin目录下的命令。

jinfo和一些参数可以动态修改JAVA进程的虚拟机参数，如动态打开或关闭打印GC日志。
jmap -heap pid：显示当前堆内存初始化配置+各区使用情况
jmap -dump:format=b,file=heapDump pid：打印堆快照，用jhat查看
jmap -histo:live pid会触发Full GC，GC结束后就知道live data大小，用来计算老年代应该设置的大小：live data*1.5

207.讲讲类加载机制？都有哪些类加载器？类加载器应用？什么是双亲委托机制？tomcat可以同时部署多个应用的原因？jsp修改后不需要重启tomcat就能生效的原因？
①1）class加载各阶段过程：
1. 加载：查找并加载类的二进制数据（ClassLoader将类的class文件中的二进制数据转化为方法区中运行时数据结构，然后在堆区创建一个该类的Class对象，用来封装类在方法区的这些数据）
2. 连接：
    - 验证：确保被加载的类的正确性
    - 准备：为类的静态变量分配内存，并将初始化默认值（类的实例变量还没有）
    - 解析：把类中的符号引用转换为直接引用
3. 初始化：为类的静态变量赋予正确的初始值
2）每个类或接口被Java程序“首次主动使用”时才初始化他们。主动引用：创建类的实例、访问类或接口的静态变量或方法、反射、初始化一个类的子类、标明为启动类的类、动态语言支持。
②1）根加载器：加载java核心库；2）拓展类加载器：加载jre\lib\ext下的类；3）应用加载器：加载classpath下的类；4）自定义加载器。③应用：类库隔离、字节码解密和热部署。
④双亲委托：先将加载任务委托给父类去加载，父类无法完成加载自己才去加载。好处：安全（jvm不会加载黑客自定义的java.lang.String类）、唯一性（类加载器和类一同确立它在jvm的唯一性）。
⑤tomcat自定义了CommonClassLoader（类库被tomcat和所有web应用共同使用）、CatalinaClassLoader（被tomcat使用，web应用不可见）、SharedClassLoader（web共享，tomcat不可见）、WebappClassLoader（仅当前web应用可见（WEB-INFO））和JasperLoader类加载器。
原因：WebApp类加载器和Jsp类加载器通常会存在多个实例，每一个应用程序对应一个WebApp类加载器。每一个JSP文件对应一个Jsp类加载器。被修改的jsp会新建一个jsp类加载器实例。

----
### MySQL
```
索引相关的、sql优化、事务等为常考点。
```
301.mysql explain执行计划
id列：编号从1开始，子查询则编号增加。
table列：表名、别名、derived(派生表名)、null(不走表)。
select_type列：simple(不含子查询)、primary(含子查询或派生查询)、subquery(非from子查询)、derived(from型子查询)、union、union result。
type列：
 ● ALL：逐行全表扫描。如缺乏索引。
 ● index：扫描所有的索引节点，能利用上索引但是全索引扫描。如索引覆盖或利用索引进行排序。
 ● range：能根据索引做范围的扫描。如使用>、<、is null、between、in或like等运算符的查询中。
 ● ref：通过索引列可以直接引用到某些数据行。
 ● eq_ref：通过索引列直接引用某1行数据，常见于连接查询中。
 ● const、system、NULL：指查询优化到常量级别，甚至不需要查找时间。
possible_keys：可能用到的索引。
key：实际用到的索引，不能为NULL(不走索引)。
key_len列：索引最大长度。
ref列：连接查询时，前表与后表的引用关系。
extra列：
 ● using index：指使用了索引覆盖，效率非常高。
 ● using where：光靠索引定位不了，还得where判断一下。
 ● using temporary：指用上了临时表，group by与order by不同列时或别的表的列。
 ● using filesort：文件排序（文件可能在磁盘，也可能在内存)。
 ● range checked for each record：没有发现好的索引。
rows列：估计扫描多少行。

302.使用mysq索引都有哪些规则？最左原则的原因？索引是什么数据结构？二叉树、B树和B+树的区别是什么？
①索引选择规则：
- 选择维度高的列(若选择性超过20%，全表扫描比用索引性能更优，如性别选择性有50%)
- 选择where,on,group by,order by中出现的列，常用的列放到前面
- 离散度(多样性)更高的索引放在联合索引的前面
- 复合索引尽量不要有null值(若组合索引包含NULL值的列则整个组合索引无效)
- 为较长的字符串使用前缀索引
- 不要在索引列上进行运算,否则索引会失效(YEAR(adddate)<2007)
- 对修改操作要求的性能远大于查询操作要求的性能时，不应该创建索引。
- 最左原则:index abc(a,b,c)→abc、ab、c分别建了索引

②最左原则原因：多列索引是先按照第一列进行排序，然后在第一列排好序的基础上再对第二列排序，如果没有第一列的话，直接访问第二列，肯定是无序的，无法使用索引了。
③mysal的InnoDB存储引擎索引是B+树，B+树所有元素都在子节点且linked，所以遍历所有数据很方便。
④B树比二叉查找树更加‘矮胖’，利用索引查询的时候，一般不会把整个索引全部加载到内存中，而是逐一加载每一个磁盘页（即索引树上的节点），树高越挨对应的IO操作次数越少。B+树比B树的优势：1.IO次数更少：单一节点存储更多的元素；2.查询性能稳定：所有查询都要查找到叶子节点，不会出现同一个sql只是条件不同有的查询快有的查询慢；3.范围查询方便：所有叶子节点形成有序链表。

303.本地事务数据库断电的这种情况，它是怎么保证数据一致性的呢？即事务的底层原理
数据库分别是由数据库文件和日志文件两种类型的文件组成的，通常情况下，日志文件要比数据库文件大很多。数据库进行任何写入操作的时候都是要先写日志的。同样的道理，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。Undo Log记录某数据被修改前的值，可以用来在事务失败时进行rollback。Redo Log记录某数据块被修改后的值，可以用来恢复未写入data file的已成功事务更新的数据（用于数据库缓存在内存中内容的持久性）。

304.mysql有哪些存储引擎？都有什么区别？
存储引擎是针对于表的而不是针对于库的（一个库中的不同表可以使用不同的存储引擎），其中MySQL常见的四种存储引擎：
MyISAM：不支持事务、也不支持外键，优势是访问速度快；适用场景：非事务型应用、读多写少类的应用。
 ● 并发性与锁级别-使用的是表级锁而不是行级锁，读写混合操作并发性不高
 ● 表损坏修复-对任意意外关闭而损耗的表进行检查和修复操作，而事务无法恢复
 ● 支持的索引类型-支持全文索引、前缀索引
 ● 支持数据压缩
InnoDB：具有提交、回滚和崩溃恢复能力的事务安全。
 ● 通过Redo Log和Undo Log实现事务
 ● 支持行级锁
MEMORY：在内存中的内容来创建表(HASH索引)。
Merge：一组MyISAM表的组合，操作实际上是对内部的MyISAM表进行的。

305.数据库事务的特征？事务的隔离级别有哪些？MySQL InnoDB默认的隔离级别是哪个？什么是幻读？MySQL InnoDB在RR级别如何避免幻读的？
①原子性、一致性、隔离性和持久性；②1）未提交读（read uncommitted）：事务A能读取到事务B尚未commit的数据，存在脏读问题；2）提交读（read committed）:事务1读取到的是事务2已commit的最新数据，若事务1中前后有两次相同的select，可能select出来的是不同的结果，存在不重复读问题。3）可重复读（repeatable read）：在同一个事务中，相同的select读到的数据一定是一致的，但会有幻读问题。4）串行化（serializable）：所有的事务串行化执行，避免了幻读，但是性能最差。③mysql默认隔离级别是可重复读，但可避免幻读。④幻读：如事务A将全table性别为男的字段都改为女，与此同时事务B又插入了一条性别字段为男的记录，当事务A再次读取全table时发现还一行的性别没有修改的数据行，就好像发生了幻觉一样。⑤在快照读情况（不加锁简单的select操作）下，mysql通过mvcc（多版本并发控制）来避免幻读。在当前读（增删改操作和加锁的读操作）情况下，mysql通过next-key来避免幻读，如④中事务A修改性别的时候，会对全表加间隙锁，此时事务B是插入不进来数据的。

306.什么是索引？mysql常见的索引类型？Hash索引的优缺点？
①索引是存储引擎用于快速找到记录的一种数据结构，大大减少了存储引擎需要扫描的数据量。缺点是需要额外的物理空间，对表中数据的增删改时还要动态的维护索引。
②索引的类型有B-Tree索引和哈希索引。
B-Tree索引：MyISAM使用前缀压缩技术使得索引更小，但InnoDB这按照原数据格式进行存储。MyISAM索引通过数据的物理位置引用被索引的行，而InnoDB则根据主键引用被索引的行。
哈希索引：对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码，哈希码是一个较小的值。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针（哈希索引只包含哈希值和行指针）。
③Hash索引优点：检索效率非常高，可一次定位，不像B-Tree索引需要从根节点到叶子节点，多次的IO访问。缺点：因hash算法是基于等值计算的，所以对于like等范围查找hash索引无效。

307.什么是聚簇索引与非聚簇索引？什么是覆盖索引？
①先了解一下MyISAM和InnoDB两个存储引擎的索引实现方式，虽然这两种引擎都使用B+Tree作为索引，但实现方式截然不同。MyISAM索引文件和数据文件是分离的，MyISAM索引文件中这棵树的每个叶子节点分别包含索引键值和一个指向对应数据记录的物理地址。
上图是一个MyISAM表的主索引（primary key）示意图，首先按照B+Tree搜索算法搜索索引，如果指定的key存在，则取出其对应的地址，然后根据该地址去数据文件中读取对应的数据记录。在MyISAM中主索引和辅助索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点不仅有主索引的键值还保存了完整的数据记录，因此InnoDB表数据文件本身就是主索引。
这是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引（表示数据行和相邻的键值紧凑地存储在一起的一种索引）。这就要求InnoDB的表必须有主键，即使没有显示的指定，MySQL也会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这样的列，MySQL自动为InnoDB表生成一个隐含字段作为主键。但InnoDB的辅助索引的索引文件这棵树的每个叶子节点包含的是索引键值和对应的主键列。首先检索辅助索引获得主键，然后用主键到主索引中检索对应的数据记录。非聚集索引则是普通索引了，仅仅只是对数据列创建相应的索引。②InnoDB中通过普通索引检索数据，需要二次检索的过程（先检索到主键，再通过主键去数据文件中检索真正的数据）。如果一个索引包含所有需要查询的字段的值，不需要对主键索引进行二次查询，这种索引称为覆盖索引。

背景：create table A(
		  id varchar(64) primary key,
		  var int,
		  ...
		 )
在id、ver有联合索引，共1w条数据。该表有几个很长的字段varbinary(3000)。
问题：为什么select id from A order by id特别慢，而select id from A order by id,ver特别快？
原因：猜测是InnoDB引擎。因id为聚簇索引，又有多个比较长的列。导致页比较多，沿id查找时要跨好多页。而id和ver的联合索引是非聚簇索引，并没有放数据行，只含有指向主键列的指针。因此次索引体积较小，在内存中查询速度将非常快。推断1：如果是MyISAM引擎，将不存在这个问题。推断2：如果没有过长的几个插入字段，差别也不会这么大。

308.为什么InnoDB表不建议使用过长的字段作为主键？要建议用自增列做主键？自增主键可能的问题？
①因为InnoDB中所有的辅助索引都引用主索引列，过长的主索引会让辅助索引变得过大。②1）InnoDB的主键采用了聚簇索引，叶子节点下有行数据，因此节点的分裂将会比较慢。主键如果是无规律的，将会加速叶子节点的分裂，效率会很低。2）主索引文件比较大，能存放在缓存中的主索引和数据行不多，移动数据可能导致InnoDB从磁盘中读取未在缓存中命中的目标页到内存中，大量的分裂将导致大量的随机I/O产生。总结：在InnoDB表中，尽量用与业务无关的递增的整型作为主键，这时候写入顺序是自增的，和B+数叶子节点分裂顺序一致的，存取效率是最高的。主键自增的索引树是相对平衡较好的树，查询效率是最高的。②可能的问题：对于高并发工作下，InnoDB中按主键顺序插入可能会造成明显的争用。因为所有的插入都发生在这里，所以并发插入可能导致间隙锁竞争。

309.count(*)、count(1)和count(field)区别？
count(*)是对不为null的行进行计数，因此某一行只要不是所有列都为null，就会被计数。count(*)自动会优化指定到某一个字段。
count(field)是对field列不为null的行进行统计，因此某一行的该列为null，则不予计数。
count(1)和count(*)都是统计表的总行数，两者执行结果相同。表上没有主键或者唯一键索引，两者都走全表扫描；表上有主键或者唯一键索引，那么走主键或者唯一键索引。

310.数据库锁都有哪些？悲观锁和乐观锁的区别？
①1）按锁模式：共享锁，如select...from lock in share mode；排它锁，如select..from for update；同一资源上不能同时共存共享锁和排它锁，在升级排它锁前，必须等该资源上的其它共享锁释放。
2）锁粒度：表级锁（不会出现死锁）、页级锁和行级锁。当一个表中的某一行被加上排它锁后，该表就不能再被加表锁。
T1:update table set c1='hello' where id=10;
T2:update table set c1='world' where id=20;
若id有索引，两行各加排它锁。若id无索引，T1对整表所有行加行锁，T2等待。
next-key：包含了记录锁和间隙锁，即锁定一个范围且锁定记录本身。
3）使用方式：乐观锁（适用于读多写少）、悲观锁（适用于频繁更新数据情况）。
②悲观锁：总是假设最坏的情况，每次在操作数据之前都会先上锁，操作完释放锁。乐观锁：每次操作数据都不会上锁，更新的时候判断一下在此期间其它线程有没有更新过这个数据，如果发现被修改了，返回给调用者进一步处理。乐观锁需要开发者自己去实现。

311.对sql做过优化吗？说说你的SQL优化之道？
①1> 使用慢日志查询：1.开启慢查询日志；2.记录没有使用索引的查询；3.记录查询时间超过0.5秒的sql。
2> 分析有问题SQL：1.分析慢查询日志（查询次数多时间长sql、没有命中索引sql、io大的sql）；2.使用explain执行计划。
3> SQL优化：1.count(*)→count(id)；2.子查询→join；3.group by→子查询；4.避免列上进行计算；5.LIKE模糊查询避免%%；6.避免使用NULL。
4> 索引优化：1.where、group by、order by、on后出现的列；2.索引字段尽量小；3.离散度大的索引放在联合索引的前面；4.使用覆盖索引。
5> 数据库结构优化：1.尽量使用简单的数据类型（少使用大数据类型）；2.尽量使用not null；3.表的水平拆分和垂直拆分。
②show profile：分析性能，查询各个sql执行时间、每个sql详细时间耗费和cpu、io消耗信息。
show processlist：显示有哪些线程在运行、当前所有的连接数、通过当前的连接状态识别有问题的查询语句。

312.如果让你来设计高并发高可用的数据库系统，你会从哪些方面考虑？
// TODO

313.如何解决分库分表的主键问题？分布式唯一id生成方法？
1.数据库自增生成全局唯一递增id，缺点：只能单机
改进：每个写库设置不同的自增长初始值以及相同的增长步长(库数量)，缺点：丧失了绝对递增性
2.单点批量id生成服务，改进：单点+备用服务。缺点：需要远程调用。
3.uuid，缺点：无法保证递增，uuid太长作为主键索引效率低。
4.取当前毫秒数，缺点：并发量不能超过1000。
5.snowflake算法：64位long型的ID，其中1位标志位，41位的时间戳（毫秒数），10位表示不同的机器（其中5位代表数据中心，5位代表数据中心内机器的id），12bit作为毫秒内序列号。该算法单机每秒理论上最多可生成400W个ID。

314.MySQL线上遇到过哪些问题？如何定位和解决的？
eg：死锁问题
隔离级别为可重复读。
情景一(c2为普通索引)：
begin:
A = update T set c1=1 where c2=2;
if (A is fail){
  insert into T(c1,c2) value(1,2);
}
commit;

若update操作的记录不存在，且此时两个事务t1,t2同时执行上述代码时:
1> t1执行update语句，记录不存在不会加行锁，但会加上间隙锁，间隙锁锁住表T c2 in (1,+∞) 的数据。
2> t2执行update语句，同时加上间隙锁（间隙锁重复加不会冲突），锁住表T c2 in (1,+∞) 的数据。
3> t1执行insert语句，试图插入但被t2持有的T表(1,+∞)间隙锁阻塞
4> t2执行insert语句，试图插入但被t1持有的T表(1,+∞)间隙锁阻塞
解决方案：
避免更新或者删除不存在的记录，虽然更新存在的记录也会产生间隙锁，但是间隙锁锁住的范围会更小；更新不存在的记录会锁住意想不到的区间范围，极易导致死锁问题。

需要注意的是：
非唯一索引更新已存在记录：加行锁和gap锁
唯一索引更新已存在记录：仅加行锁
非唯一索引/唯一索引 更新不存在记录：加gap锁

情景二(c2为普通索引)：
begin:
insert into T(c1,c2) value(0,1);
update T set c1=0 where c2=1;
commit;

当两个事务t1,t2同时执行上述代码时:
1> t1执行insert语句，成功插入一条新的记录record1(1,0,1),并对当前记录加上id=1 这条记录的X锁（排它锁）
2> t2执行insert语句，生成记录record2(2,0,1), 并加上id=2 这条记录的X锁。
3> t1执行update语句，需要对所有符合条件的记录加X锁，已持有record1的X锁，等待获得record2的X锁。
4> t2执行update语句，需要对所有符合条件的记录加X锁，已持有record2的X锁，等待获得record1的X锁。

解决方案：
改成 update T set c1=0 where c2=1 and id=xx;锁的粒度保证尽量小。

----
### 分布式缓存
401.redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高？
①区别：1）redis支持的数据类型更多。2）redis有原生支持的持久化功能。3）redis有原生支持的集群模式。
②缓存快的原因是因为纯内存操作+非阻塞IO多路复用机制，而redis比memcache更快的原因是：memcached多线程模型引入了缓存一致性和锁，加锁带来了性能损耗。单线程避免了多线程的频繁上下文切换的问题。

402.redis都有哪些数据类型？分别在哪些场景下使用较为合适？redis持久化方式都有哪些？各有什么优缺点？
①1）string：做kv缓存。2）hash：缓存结构化的数据。3）list：可当队列和栈来用。4）set：求集合的交并差集，如微博的共同好友。5）sorted set：排行榜。
②RDB:内存到硬盘的快照，定期更新。缺点：耗时，耗性能(fork+io操作)，易丢失数据。AOF:写日志。缺点：体积大，恢复速度慢。

403.redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？
①主节点将自己内存中的数据做一份快照，将快照发给从节点，从节点将数据恢复到内存中。之后再每次增加新数据的时候，主节点以类似于mysql的二进制日志方式将语句发送给从节点，从节点拿到主节点发送过来的语句进行重放。②分片方寻址方式：客户端分片、基于代理的分片、路由查询分片和redis-cluster。

404.介绍一下redis的过期策略？手写一下redis的LRU代码实现？
①定期过期+惰性过期。定期过期：redis每隔一段时间随机抽取一部分设置了过期时间的key，检查是否过期，如果过期就删除，缺点是key过多时有些key可能没有扫描到而未删除。惰性过期：只有使用key时才判断key是否已过期，过期则清除并返回null，缺点是会存在大量已过期的key依然占用内存。即使两种方式结合，如果还是有大量key堆积在内存里导致内存耗尽，此时会在键空间中，采用LRU算法移除最近最少使用的key。
②LRU：new LinkedHashMap<K, V>(capacity, DEFAULT_LOAD_FACTORY, true);
//第三个参数置为true，代表linkedlist按访问顺序排序，可作为LRU缓存；设为false代表按插入顺序排序，可作为FIFO缓存
LRU算法实现：1.通过双向链表来实现，新数据插入到链表头部；2.每当缓存命中（即缓存数据被访问），则将数据移到链表头部；3.当链表满的时候，将链表尾部的数据丢弃。

405.Redis线程模型？Redis内存模型？
// TODO

406.缓存穿透、缓存击穿、缓存雪崩解决方案？缓存与数据库双写不一致解决方案？
①缓存穿透：指查询一个一定不存在的数据，如果从DB查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到DB去查询，大量并发的请求不存在的数据可能导致DB挂掉。
解决方案：1.查询返回的数据为空，仍把这个空结果进行缓存；2.布隆过滤器：将所有存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对DB的查询。
②缓存击穿：对于设置了过期时间的key，在某个时间点过期了，恰好这时间点对这个key有大量的并发请求过来，这些请求发现缓存过期一般都会从DB加载数据并写回到缓存，这个时候大并发的请求可能会瞬间把DB打垮。
解决方案：1.使用互斥锁：当缓存失效时，不立即去load db，先使用如redis的setnx去设置一个互斥锁，操作成功后的线程才请求db并写回到缓存，否则重试get缓存的方法。2.永不过期：物理不过期，但逻辑过期（后台异步线程去刷新）。
③缓存雪崩：设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部打到了DB，DB瞬时压力过大而雪崩。与缓存击穿的区别：雪崩是多个key，击穿是针对一个key的缓存。
解决方案：将缓存失效时间错开，比如可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样多个缓存的过期时间相同的概率就会降低，就很难引发集体失效的事件。

407.如何设计系统应对redis崩溃问题？如果保证redis高可用？
①事前：redis高可用，主从+哨兵+redis cluster，避免全盘崩溃。事中：本地缓存+hystrix限流&降级，避免DB被打垮。事后：redis持久化，快速恢复缓存数据。
②高可用：一主+多从+多哨兵。高并发：单主用来写入数据，多从用来查数据。存大数据量：每台不再是容纳完整的数据，采用redis集群让每台仅存放完整数据的一部分。

----
### 消息队列
501.为什么使用消息队列？引入消息队列有什么缺点？
①异步处理、应用解耦、流量削峰、日志处理和消息通信。②缺点：可用性降低：MQ挂了整套系统崩溃；复杂性提高：要考虑消息不重复、顺序性等问题；一致性问题：有的系统成功消费了这个消息，而有的系统失败了就出现了数据一致性问题。

502.kafka、activemq、rabbitmq、rocketmq都有什么优点缺点？
● kafka比ActiveMQ和RabbitMQ更有分布式优势，partition可以冗余存储，若一个partition挂了，可以选主切换到另一台机器继续使用。
● ActiveMQ和RabbitMQ是消费之后就删除消息，没有重复消费的功能。kafka队列中的内容按策略存储一定的时间，消费者自己控制偏移量来读取数据。
● 传统的消息队列只有两种模式：要么queue，要么发布订阅。而kafka通过consumer group和队列数据不删除两个概念更加灵活。
● kafka对于有集群要求，尤其是如果是大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的。
● kafka创建topic是一个比较重的操作，因为是分布式需要同步到其他的broker中间要经过zookeeper。而rabbitmq创建几万个topic是很容易的。
● rabbitmq是功能最丰富，最完善的企业级队列。erlang语言难度较大。不支持事务。
● activemq相对来说，显的老套了一些。支持事务。但社区不活跃，没有经过大规模吞吐量场景的验证。

503.引入消息队列之后如何保证高可用？
1）rabbitmq采用镜像集群模式，部署在多台机器上形成集群，将消息写到某个queue时会自动同步到其它机器上，所有机器都含有完整的数据。2）kafka是天然分布式的，一个topic数据会分散存放多台机器上，每个partition只存放一部分数据。kafka0.8以后提供了HA机制，每个partition的数据都会同步到自己的其它replica副本机器上，让含有相同数据的机器形成集群，从这个集群中选举出leader，其它机器为follower。写和读消息都和leaer打交道，leader同步给follower们，如果leader挂了，从其它follower中重新选取leaer出来然后顶上去。

504.消息的重发补偿解决思路？消息的幂等性解决思路？
①无论哪种mq重复消息是不可能100%避免的，如kafka中，消费者是每隔一段时间把已消费的索引位置提交给kafka，在某些消息已经消费完但是还没有提交之时，kafka被重启了，那么重启后将会推送已消费的重复消息给消费者。这种问题通常不是mq来保证的，而是由我们开发来保证的，一般通过消息消费的幂等性来保证。②一般会为每条消息生成一个唯一的id，然后根据具体业务来处理。如数据库根据消息唯一id建立唯一索引，重复的消息入库会失败。或者消费之前先根据这个id去redis中查询一下，如果不存在才消费并将id写入redis，否则丢弃。

505.如何保证消息不丢失？
1）rabbitmq：1>生产者→mq：开启确认模式，mq接收到消息后会回传给生产者ack消息，如果失败或者长时间没有回传，则生产者重发消息。2>mq本身：开启持久化机制，mq挂了恢复后会读取持久化的数据。3>mq→消费者：关闭自动确认机制改为手动确认，默认消费者收到消息后就发送ack给mq，若此时没来得及处理消费者挂了，该消息会丢失，如果由消费者消费完消息后再发送ack即可保证。2）kafka：1>生产者→mq：设置ack=all，即不仅仅leader，还要所有follower都确认才算成功，否则重试。2>mq本身：当某leader挂了，然后选举某follower作为leader时，恰好有数据老leader没有同步给该follower时，会丢失数据。同理设置生产者ack=all。3>mq→消费者：关闭自动确认为由程序消费完成后手动确认。

506.如何保证消息的有序性？
消息队列保证全局有序还是比较困难的，但是可以保证局部有序性。首先生产者需要顺序发送消息，且不能异步确认，消费者不能开启多线程并行消费。rabbitmq：一个queue如果对应多个消费者同时去消费，会导致消息乱序。可以拆分成多个queue，每个queue对应一个消费者，将有序的消息序列扔到同一个queue里面来解决。kafka：一个topic对应多个partition，容易导致消息乱序。一般通过生产者发送消息时指定key或者partition，让有序的消息序列发往同一个partition，1个partition只能被一个消费者消费来解决。

----
### 分布式存储引擎
// TODO
es是如何实现分布式的？
es写入数据的工作原理是什么啊？es查询数据的工作原理是什么？
es在数据量数十亿级别场景下如何提高查询性能啊？
es生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？

----
### 分布式系统
601.为什么要将系统进行拆分？分布式服务有哪些常用的框架？分布式服务框架作用是什么？
①All In One痛点：1>代码到处拷贝：如各个业务线都通过自己DAO写SQL访问user库来获取用户数据。2>维护困难：代码经常出现修改冲突。A调用了B的代码，A需要重新测试。修改一个功能点，整套代码需要上线。3>复杂性扩散：如从db获取用户数据中加入了缓存，各个业务线需要关注缓存的引入被迫升级。拆分后的好处：
提高了代码复用性、屏蔽底层复杂度、数据库解耦、每个人只维护自己的服务就可以了。缺点：分布式事务无法保证强一致性。
②常用分布式服务框架主要有阿里系的dubbo和spring家族的spring cloud栈。③各系统之间调用虽然可以使用http接口调用，但http主要是为浏览器服务的，含有大量比较冗余的header不适合接口间通信。分布式服务框架主要解决了不同系统间高性能的通信、超时重试、负载均衡、服务接口自动上下线的感知、有效的管理服务的url等问题。

602.说一下dubbo的工作流程？讲一下一次rpc请求的流程？注册中心挂了可以继续通信吗？
①1.服务提供者在启动时，向注册中心注册自己提供的服务，如注册中心就知道了某服务X部署了3台机器，每台机器的ip地址和端口号及服务的url。2.服务消费者在启动时，向注册中心订阅自己所需的服务。3.注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。4.服务消费者从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。5.服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。
②服务消费者先咨询注册中心服务X有没有且部署在哪些机器上，注册中心返回服务提供者的地址列表给服务消费者，服务消费者请求自己的代理层，然后再请求dubbo的集群层，集群层通过负载均衡选取服务X的某台机器A，然后将请求转发到A机器的代理层，代理层再请求机器A，机器A处理完请求后将相应发回给机器A的代理层，机器A的代理层返回给服务消费者的代理层，然后再返回给服务消费者。③还可以继续通信，初始化时消费者会将服务提供者地址列表进行本地缓存，但不能注册新服务。监控中心宕掉也正常通信，只是会丢失部分采样数据。

603.dubbo支持哪些常用通信协议和序列化协议？知道hessian的数据结构吗？PB知道吗？为啥他的效率最高？
①通信协议：
dubbo：默认协议，单一TCP长连接、NIO异步、Hessian序列化、适用于小数据量高并发，消费者远多于提供者。原因：通过单一连接，保证单一消费者不会压死提供者，长连接，减少连接握手验证等，并使用NIO复用线程池。
rmi：采用阻塞式短连接和JDK标准序列化方式。消费者与提供者个数差不多，可传文件，一般较少用。
hessian：走hessian序列化协议，适用提供者比消费者个数多，可传文件。
http：走json序列化，适用提供者比消费者个数多。
序列化协议：
Hessian二进制序列化：实现机制是着重于数据，把对象所有的属性当成一个Map来序列化。Integer a=1→I 1。只传成员属性值和值的类型，不传方法或静态变量。
Java标准二进制序列化：把要序列化的对象类的元数据和业务数据全部序列化为字节流，较可靠。
②protobuf：一种数据交换的格式，和JSON，XML一样；pb文件使用一个唯一的id（数字）来代替json里复杂的key，这样只要数据发送方和接收方都用同一套模板文件来解析，可大大提高传输效率。

604.dubbo负载均衡策略和集群容错策略都有哪些？动态代理策略都有哪些？
①负载均衡策略：按权重进行随机、轮询、最少活跃调用数、一致性hash。nginx负载均衡：轮询(默认)、指定权重、ip_hash、fair(第三方，按后端服务响应时间)、url_hash(第三方)。②集群容错：failover（失败自动重试其它机器）、failfast（一次调用失败立即失败）、failsafe（出异常忽略掉）、failback（失败了后台记录请求，定时重发）、forking（并发调用多个提供者，只要一个成功就返回）、broadcast（逐个调用所有提供者）。读操作建议使用failover，默认重试两次失败切换其他服务器。写操作建议使用failfast，发一次调用失败就立即报错。③动态代理：没有使用CGLib进行代理，而是使用JDK和Javassist来进行动态代理。
注册中心：Multicast（广播）、zookeeper、Redis、Simple（本身就是一个普通的Dubbo服务）
dubbo配置覆盖优先级：方法级优先，接口级次之，全局配置再次之。如果级别一样，则消费方优先，提供方次之。

605.如何基于dubbo进行服务治理、服务降级、失败重试以及超时重试？
// TODO

606.为什么要使用分布式锁？使用redis如何设计分布式锁？使用zk如何实现？这两种有什么区别？
①当某个变量同一时间只能被一个线程修改时，一般通过锁来实现。锁的本质是在某个地方做一个标记，这个标记每个线程都能看到，标记不存在时可设置该标记，设置标记成功的线程才能执行修改该变量的动作。其余线程发现已经有标记，只能等这个线程执行完且取消标记后再去尝试设置标记，这个标记可以理解为锁。java中的synchronized和ReentrantLcok只能对一个进程起作用，但分布式系统是多进程且部署在不同机器上的，需要分布式锁来解决。
①redis:
1.线程A：setnx(上锁的对象,超时时的时间戳t1)，如果返回true，获得锁。
2.线程B：用get获取t1，与当前时间戳比较，判断是是否超时，没超时false，若超时执行第3步。
3.计算新的超时时间t2，使用getset命令返回t3，如果t1==t3，获得锁。如果t1!=t3说明锁被其他线程获取了。
4.获取锁后，处理完业务逻辑，再去判断锁是否超时，如果没超时删除锁，如果已超时，不用处理（防止删除其他线程的锁）。
②zk:
1.客户端对某个方法加锁时，在zk上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点node1;
2.客户端获取该路径下所有已经创建的子节点，如果发现自己创建的node1的序号是最小的，就认为这个客户端获得了锁。
3.如果发现node1不是最小的，则监听比自己创建节点序号小的最大的节点，进入等待。
4.获取锁后，处理完逻辑，删除自己创建的node1即可。
③区别：redis中当客户端挂了，只能等待超时时间之后才能释放锁。zk需要创建znode开销大，但模型简单易用，较为牢靠。

607.为什么要使用分布式事务？分布式事务的解决方案？若在通信过程中出现网络原因，如何解决？
①一次大的操作由不同的小操作组成，这些小的操作要么都执行成功，要么当某一个小操作执行失败时，已经执行了的小操作必须全部正确回滚。如果这些小操作都是在一个数据库上执行，可以借助数据库本地事务来完成。如果这些小操作分布在不同的服务器和数据库，就需要分布式事务了。
②解决方案：
1.XA协议两阶段提交（2PC）：事务管理器+多个数据库的本地事务
  ● 投票：事务管理器挨个询问数据库是否准备好了，每个数据库收到询问后执行本地事务但不提交，并返回是否执行成功。
  ● 事务提交：当事务管理器收到都准备ok后，通知每个数据库执行提交。
  ● 出错后，事务管理器发起回滚通知。
3PC（1.增加超时机制;2.两阶段间插入准备阶段）
2.消息事务+最终一致性：
  ● A系统向消息中间件发送一条预备消息
  ● 消息中间件保存预备消息并返回成功
  ● A执行本地事务
  ● A发送提交消息给消息中间件
3.TCC编程模式(补偿机制、消息重试+接口幂等)：
一个编程框架，将整个业务逻辑分为三块：Try、Confirm和Cancel(服务提供者提供,需幂等)三个操作。

608.集群部署时session如何处理？
1）粘性session：某个用户在某台机器上创建了session，后续该用户其它请求都转发到这台服务器上，缺点是缺乏容错。2）session复制：任何一台服务器session发生变化，都要同步到其它服务器上，缺点是网络负荷较大。3）共享session：由服务器存储session改为redis存储。

609.zookeeper原理知道吗？项目中都用到zookeeper哪些功能？其实现算法知道吗？说一下大概原理？
zk是一个分布式的且开源的分布式应用程序协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。提供了文件系统和通信机制功能。
文件系统：znode类型：永久性(断开连接后，节点依然存在)、永久编号性、临时性(断开连接该节点删除)、临时编号性。
通知机制：客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。
实现功能：1.命名服务、2.配置管理、3.集群管理、4.分布式锁、5.队列管理
配置管理：逐个修改多台机器上应用程序的配置比较困难，现把这些配置全部放到zk上去，保存在zk的某个目录节点中，然后所有相关应用对这个目录节点进行监听，一旦配置信息发生变化，每个应用就会收到zk的通知，然后从zk获取新的配置信息应用到系统中。
集群管理（是否有机器退出和加入、选举master）：所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与zk的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知。每次选取编号最小的机器作为master就好。

610.为什么选择netty？原生的NIO在JDK 1.7版本存在epoll bug？netty线程模型？说说netty的零拷贝？netty内部执行流程？netty重连实现？
①如分布式系统间需要频繁的进行rpc通信，是否高效的IO操作是影响高性能、高可靠性的网络服务的关键。jdk提供NIO的api使用比较复杂，还可能触发epoll bug。而netty使用简单并预置了多钟编解码器，支持多种主流协议，是一款用于创建高性能网络应用程序的框架。②selector的select方法，因为底层的epoll函数可能会发生空轮询，从而导致cpu100%。③通过Reactor模型基于多路复用器接收并处理用户请求，内部实现了两个线程池（boss线程池和work线程池），其中boss线程池的线程负责处理请求的accept事件，当接收到accept事件的请求时，把对应的socket封装到一个NioSocketChannel中，并交给work线程池，其中work线程池负责请求的read和write事件。④指计算机在网络上发送文件时，不需要将文件内容拷贝到用户空间而直接在内核空间中传输到网络的方式，减少了CPU消耗。netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。⑤// TODO

----
### 微服务
701.说说CAP理论、BASE理论？怎么考虑数据一致性问题？最终一致性的实现方案？
①一致性（Consistency）、可用性（Availabbility）和分区容错性（Partition tolerance）。在一个分布式系统中，在出现节点之间无法通信（网络分区产生），你只能选择可用性或一致性，无法同时选择他们。即要么AP要么CP。②Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）。通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但要达到最终一致性。③④// TODO

702.什么是服务熔断？什么是服务降级？
①当下游服务因访问压力过大而响应变慢或失败（即在固定的时间内，调用下游接口超时次数超过一定数量），上游服务为了保护系统整体的可用性，可以暂时切断对下游服务的调用。这种牺牲局部从而保全整体的措施叫熔断，如Spring Cloud Hystrix框架。②当服务架构整体的负载超出了预设的上限阈值时，为了保证重要的服务能正常运行，将一些次要的服务进行暂停，从而释放资源以保证核心链路的正常运作。

703.你怎么理解RESTful？如何理解RESTful API的幂等性？如何保证接口的幂等性？
// TODO

----
### 设计模式
```
一般只考常用的设计模式，建议结合一些经常接触到的例子来记忆，不容易忘。如果能结合自己的项目来回答面试那最好了。
```
设计模式原则：1.单一职责原则（只一个类只完成单一的功能）；2.开闭原则（对扩展开发，修改关闭）；3.里氏替换原则（引用父类的地方都可以透明的使用其子类）；4.依赖倒置原则（面向接口编程，而非面向具体实现编程）；5.接口隔离原则（接口功能划分明确，一接口一功能）；6.迪米特法则（一个类尽可能少的与其它类交互）。

单例模式：保证一个类仅有一个实例，并提供一个访问它的全局访问点。懒汉式、饿汉式、双重校验锁、静态内部类、枚举类。

代理模式：一个客户不想或者不能够直接引用一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。
静态代理：由程序员创建代理类，运行前代理类.class已存在；动态代理：代理类在程序运行时通过反射动态生成。
动态代理使用情景：要代理的功能确定了，想批量的给一些类或方法生成代理类。如给某个包下所有以add开头的方法调用前后打印一些日志，或所有DAO结尾的类的所有方法执行前开启事务，执行后提交事务，抛异常时回滚事务。
cglib和jdk动态代理区别:
jdk动态代理让代理类和目标类实现同一个接口(兄弟关系)，使用反射机制(核心类：Proxy\InvocationHandler)。
cglib生成一个目标类的之类(父子关系)，cglib用ASM直接操作字节码达到运行时动态创建类的效果(核心类：Enhancer\MethoInterceptor)。
mybatis用的jdk动态代理，spring两者都用(有接口用动态代理，没有接口用cglib，还可自行配置)。
静态代理实现：声明一个目标对象和代理对象的共同实现的且含有一个抽象方法的接口Subject【抽象对象角色】。目标对象实现类Target实现了该接口，并在该方法中实现具体需要做的事情【目标对象角色】。代理实现类Proxy也实现该接口，并持有抽象对象角色接口的引用，且实现方法中调用持有引用的实现方法，可在调用前后加入代理类自己的逻辑。
class Proxy implements Subject {
	private Subject target;
	public Proxy(Subject target){ this.target=target; }
	@Override
	public void doSomeThing(){ before();target.doSomeThing();after(); }
}

适配器模式：将一个类的接口转换成客户希望的另外一个接口。使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。
已知接口和实现类有：日本110v电源接口Power110v（该接口含有110v工作的抽象方法do110v）【抽象目标角色】、日本110V接口实现类Power110vImpl、中国220v电源接口Power220v（该接口含有220v工作的抽象方法do220v）【抽象源角色】、中国220V接口实现类Power220Impl、日本电饭煲实现类。需求是用中国220v电源冒充日本110v电源运行日本电饭煲。
实现：定义一个电源适配器实现类【适配器角色】，该类实现了日本110v电源接口，并持有中国220v电源接口的引用，在110v工作的方法中调用持有引用的220工作的方法。
class PowerAdapter implements Power110v{
		private Power220v power220v;
		public PowerAdapter(Power220v power220v){ this.power220v=power220v; }
		public void do110(){ power220v.do220v; }
}
创建中国220v电源实例，并作为参数创建电源适配器实例。将电源适配器实例作为参数创建电饭煲，电饭煲开始工作。

装饰者模式：动态地给一个对象添加一些额外的功能，比继承关系更有弹性的替代方案。
案例：装饰者模式在Java IO流上得到了很好的运用。
MyReader //专门用于读取数据的公共方法类
  |--MyTextReader // 读取文本数据的类
  |--MyMediaReader // 读取媒体数据的类
  |-- ...          // 读取其它数据类型的类
需求：将上述N个具体类在不修改原类的情况下分别增加一个缓冲功能。
如果采用继承的方式，那么每个具体类都要生成新的子类而变成体系臃肿，而采用装饰者模式只需要增加一个类即可完成，高内聚低耦合。
实现：class MyBufferReader extends MyReader {
    private MyReader r;
    MyBufferReader(MyReader r) { }
    ... //拓展了MyReader类的其它方法
}
使用：new MyBufferReader(new MyMediaReader());

代理模式VS装饰模式：两者都现实了各自统一的抽象接口，采用了组合方式，且增加了新功能。但代理模式在代理类中已经指定好了被代理的对象，而装饰模式在包装类需要客户端传入被装饰的是哪一个类。

观察者模式(发布/订阅模式)：定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态发生变化时，会通知所有观察者对象，使它们能够自动更新自己。
需求：某个微信公众号服务，不定时发布一些消息，关注公众号就可以收到推送消息，并显示给用户，取消关注就收不到推送消息。
实现：将所有具体观察者抽象出一个接口【抽象观察者角色】，该接口包含了一个得到主题通知更新自己的抽象方法，所有观察者实现该接口【具体观察者角色】。主题类将所有观察者对象保存在一个List里，并对外提供了一个可以增加和删除观察者对象的方法，当内部状态变化时，给所有已登记的观察者发出通知【具体主题角色】。

策略模式：定义一系列的算法，把它们一个个封装起来, 并且使它们可被互换。
需求：卖书系统对不同的会员等级折扣力度不一样，初级0折扣、中级9折、高级8折。
实现：抽象折扣接口含有提供计算图书价格的抽象方法【抽象策略】，初级、中级和高级分别实现该接口并实现不同的打折策略【具体策略】。价格类持有一个抽象策略对象的引用和传入具体策略对象的构造方法，且对外提供根据不同的具体策略计算价格的方法【环境角色】。

工厂模式：将需要的产品和工厂结合在一起，从而得到一个具体需要的产品的一个过程，而无需知道这个产品具体是由谁生产的，屏蔽了产品的具体实现。
分为简单工厂模式-工厂模式-抽象工厂模式。
简单工厂通过构造时传入的标识来生产产品，不同产品都在同一个工厂中生产。但这种判断会随着产品的增加，需要不停的switch case，不利于扩展和维护。而工厂模式将工厂类分开，增加一个新产品时，需要增加一个工厂类和一个产品类，对已有的工厂和产品无影响，一个工厂生产一个产品。但无法解决一个工厂可以生产多个产品的问题，如nike工厂不仅生产球衣，还生产球鞋和篮球，同样adidas生产球衣、球鞋和篮球。而抽象工厂模式中，一个工厂可以生产多个产品，每一类产品定义一个抽象接口，每个工厂具有生产不同产品的方法。
案例：Hibernate通过换不同的数据库方言和驱动用工厂模式产生不同的连接。
简单工厂实现：抽象产品接口含有一个创建产品的抽象方法【产品规则】，每一个产品实现该接口并实现自己的方法【工厂产品】。工厂对外提供一个根据不同的名称/类型产生不同产品的方法【工厂】。

构建者模式：对象的创建模式(Builder模式)，将类的构建和表示进行分离，隐藏了复杂对象的创建过程。
案例：lombok的@Builder，当创建一个复杂的bean时，因内部结构比较复杂，属性比较多。如果为每一个属性生成一个set方法，创建这个bean时代码会比较冗长，行数比较多，如果生成一个多个参数的构造方法时，因参数过多，特别是相同类型的参数放到一起时，构造该bean时很容易搞混。而使用builder模式再加上链式调用会比较清晰。如Student s=new Student.Builder().name("a").age(18).sex("男").build();

工厂模式VS建造者模式：工厂方法模式注重的是整体对象的创建方法，而建造者模式注重的是部件构建的过程，旨在通过一步一步地精确构造创建出一个复杂的对象。

享元模式：利用共享对象池提高对象的充分复用性。
案例：JDK中，String就使用了享元模式，String对象是final的，一旦创建就不可改变，jdk确保一个字符串常量在常量池中只有一份拷贝，减少了内存消耗。
实现：一般将一些对象公共不变化的部分抽取出一个新的对象，让这些对象通过单例模式引用这一份公共对象。

----
### 常用框架原理
801.filter、interceptor和Aspect的区别？执行顺序？
①filter只能拿到原始http的请求和响应信息，获得一些参数。拿不到由哪个Controller的哪个方法处理的。因为filter是J2EE规范定义的。因为Controller是SpringMVC定义的东西，想获取真正处理请求方法的信息需要使用interceptor(因它有第三个参数Object handler)，但interceptor无法拿到真正方法参数的值。想拿到真正处理请求方法参数的值需要使用Aspect，但Aspect(只有一个参数ProceedingJoinPoint pjp)是直接拿不到原始http请求和响应的对象。
②执行顺序：filter→Interceptor→ControllerAdvice→Aspect→Controller

802.Spring框架中都用到了哪些设计模式？
代理模式—在Aop实现中用到了JDK的动态代理。
单例模式—在spring配置文件中定义的bean默认为单例模式。
模板方法—用来解决代码重复的问题。比如RestTemplate、JmsTemplate、JpaTemplate。
工厂模式—BeanFactory/ApplicationContext用来创建对象的实例。
策略模式-1：加载资源文件的方式，使用了不同的方法，比如：ClassPathResourece、FileSystemResource、ServletContextResource等，但他们都有共同的接口Resource；2：在Aop的实现中，采用了两种不同的方式，JDK动态代理和CGLIB代理。

803.Servlet生命周期？Spring中Bean的生命周期和作用域各是怎样的？Spring对象初始化bean时机？bean的作用域？循环依赖怎么处理？
①Servlet生命周期：init()进行初始化→service()处理客户端的请求→destroy()方法终止→JVM回收Servlet。
②1.首先容器启动后找到Bean定义信息调用构造方法并将其初始化;
2.按照Bean定义配置信息，注入所有的属性;
3.如果Bean实现了各种XXXAware接口，会回调该接口的setXXX()方法;
4.如果Bean含有@PostConstruct注解，则会调用该方法;若bean实现了BeanPostProcessor接口,将调用它的postProcessBeforeInitialization接口方法；
5.如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法；
6.如果Bean配置了init-method方法，则会执行init-method配置的方法;若bean实现了BeanPostProcessor接口,将调用它的postProcessBeforeInitialization接口方法；
7.经过流程6之后，就可以正式使用该Bean了；容器关闭后，@PreDestroy调用该方法；
8.如果Bean实现了DisposableBean接口，则会回调该接口的destroy()方法；
9.如果Bean配置了destroy-method方法，则会执行destroy-method配置的方法。
③Spring对象初始化bean时机：在默认情况下，只要在Spring容器中配置了一个bean，容器在启动时就会实例化该bean，单例模式。如果在Spring配制文件时设置懒加载模式（lazy-init=”true”），在getBean时才会实例化对象。如果scope=”prototype”时，无论lazy-init的值是什么都只会在使用时才会创建，当struts2的action和spring容器整合的时候，action的scope设置成prototype。
④作用域：
singleton：单例模式，Spring IoC容器中只会存在一个共享的Bean实例；
prototype：原型模式，每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态；
request：在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会产生新的Bean，而且该bean仅在当前Http Request内有效；
session：在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请求则会创建新的实例，该bean实例仅在当前Session内有效；
global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在使用portlet context时有效。

804.Spring AOP原理？Spring AOP无法代理方法内部调用的原因？
①动态代理。②在使用Spring AOP的时候，我们从IOC容器中获取的Bean对象其实都是代理对象，而不是那些Bean对象本身，由于this关键字引用的并不是该Bean对象的代理对象，而是其本身，因此Spring AOP是不能拦截到这些被嵌套调用的方法的。

805.Spring Bean的加载过程是怎样的？
１、ResourceLoader从存储介质中加载Spring配置信息，并使用Resource表示这个配置文件的资源；
２、BeanDefinitionReader读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中每一个<bean>解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中；
３、容器扫描BeanDefinitionRegistry中的BeanDefinition，使用Java的反射机制自动识别出Bean工厂后处理后器（实现BeanFactoryPostProcessor接口）的Bean，然后调用这些Bean工厂后处理器对BeanDefinitionRegistry中的BeanDefinition进行加工处理。主要完成以下两项工作：
1）对使用到占位符的<bean>元素标签进行解析，得到最终的配置值，这意味对一些半成品式的BeanDefinition对象进行加工处理并得到成品的BeanDefinition对象；
2）对BeanDefinitionRegistry中的BeanDefinition进行扫描，通过Java反射机制找出所有属性编辑器的Bean（实现java.beans.PropertyEditor接口的Bean），并自动将它们注册到Spring容器的属性编辑器注册表中（PropertyEditorRegistry）；
4．Spring容器从BeanDefinitionRegistry中取出加工后的BeanDefinition，并调用InstantiationStrategy着手进行Bean实例化的工作；
5．在实例化Bean时，Spring容器使用BeanWrapper对Bean进行封装，BeanWrapper提供了很多以Java反射机制操作Bean的方法，它将结合该Bean的BeanDefinition以及容器中属性编辑器，完成Bean属性的设置工作；
6．利用容器中注册的Bean后处理器（实现BeanPostProcessor接口的Bean）对已经完成属性设置工作的Bean进行后续加工，直接装配出一个准备就绪的Bean。

806.SpringMVC执行流程和工作原理？
1、用户发送请求至前端控制器DispatcherServlet。
2、DispatcherServlet收到请求调用HandlerMapping处理器映射器(根据请求的url查找Handler)。
3、HandlerMapping找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器生成HandlerExecutionChain一并返回给DispatcherServlet。
4、DispatcherServlet调用HandlerAdapter处理器适配器。
5、HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。
HandlerMapping和HandlerAdapter区别：前者是用来找到url对应的处理handler对象，而不是找到url对应的处理函数。后者则是用来匹配到handler的某个具体的处理函数上，准备参数并调度执行这个函数。
6、Controller执行完成返回ModelAndView。HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。
7、DispatcherServlet将ModelAndView传给ViewReslover视图解析器，ViewReslover解析后返回具体View。
8、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）并响应给用户。

807.为什么要用Mybatis？讲一下工作原理？如何设置缓存呢？
①作用：消除了几乎所有的JDBC代码和参数的手动设置以及结果集的检索，普通javaBean映射成数据库中的记录。②原理：MyBatis应用程序通过Resources加载XML配置文件初始化Configuration，创建SqlSessionFactory，SqlSessionFactory再根据配置（配置来源于两个地方：一处是配置文件、一处是Java代码的注解）获取一个SqlSession。SqlSession包含了执行sql所需要的所有方法，可以通过SqlSession实例直接运行映射的sql语句，完成对数据的增删改查和事务提交等，用完之后关闭SqlSession。③缓存：一级缓存是SqlSession缓存，默认开启的，如未提交的事务第二次查询相同的SQL会直接从缓存中取。二级缓存是指mapper映射文件，作用域是同一个namespace下的mapper映射文件内容，多个SqlSession共享，默认不开启。

808.springboot自动配置的原理
在spring程序main方法中添加@SpringBootApplication或者@EnableAutoConfiguration，会自动去maven中读取每个starter中的spring.factories文件，该文件里配置了所有需要被创建spring容器中的bean。

809.Spring容器-ApplicationContext的启动过程
https://www.cnblogs.com/andypeker/p/7016967.html

----
### 其它
901.linux相关命令
lsof –i (4、6、协议、:端口、@ip) 列出符合条件的进程
dig:域名查询工具 [dig baidu.com]
批量替换字符串：sed -i "s/查找字段/替换字段/g" `grep 查找字段 -rl 路径`
统计log文件中异常出现的次数、排序，或者指定输出多少行多少列内容的命令：awk

902.网络七层协议和五层模型？TCP三次握手和四次挥手？为什么数据库连接比较耗资源？
①应用层(HTTP、TELNET、FTP)、表示层、会话层、传输层(TCP、UDP)、网络层(IP、ICMP)、数据链路层、物理层。前三层合并为一层应用层的为网络五层模型。
②TCP三次握手：
1:建立连接时，客户端发送SYN(i)到服务器，并进入SYN_SEND状态，等待服务器确认；(SYN:synchronous)
2:服务器收到SYN，发送一个ACK(i+1)确认，同时自己也发送一个SYN(j)，即SYN+ACK包，此时服务器进入SYN_RECV状态；(ACK:Acknowledgement)
3:客户端收到服务器的SYN＋ACK包，向服务器发送确认ACK(j+1)，此包发送完毕，客户端和服务器进入ESTABLISHED(已建立的)状态，完成三次握手。
TCP四次挥手：
1.断开连接时，客户端发送一个FIN(m)，用来关闭客户端到服务端的数据传送，客户端进入FIN_WAIT_1状态；(FIN:finish)
2.服务端收到FIN后，发送ACK(m+1)确认，表示同意客户端关闭请求了，并进入CLOSE_WAIT状态；客户端收到后进入FIN_WAIT_2状态；
3.服务端发送一个FIN(n)，用来关闭服务端到客户端的数据传送，服务端进入LAST_ACK状态；
4.客户端收到FIN后，发送一个ACK(n+1)确认，并进入TIME_WAIT状态，服务端收到后进入CLOSED状态，完成四次挥手。
③资源消耗主要集中在网络上，建立TCP连接需要三次握手，然后客户端发送认证包（用于用户验证），再进行一些连接变量的设置（比如字符集、是否自动提交事务等）。

903.说说TCP的窗口滑动机制？TCP粘包/拆包的解决办法？
// TODO

904.从输入网址到浏览器呈现页面内容，中间发生了什么？常见http状态码含义
①https://mp.weixin.qq.com/s/q9wDvplWysHCn_Bet8j5lA
②http code:301-永久性转移、302-暂时性转移、304-Not Modified（Last-Modified和ETag）、405-method not allowed。

905.java8和java9新特性
java8：
Lambda 表达式−Lambda允许把函数作为一个方法的参数。
方法引用−方法引用可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，
默认方法−默认方法就是一个在接口里面有了一个实现的方法。
Stream API−新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。
Date Time API−加强对日期与时间的处理。
Optional 类−用来解决空指针异常。
java9：
模块化-采用模块化系统的应用程序只需要这些应用程序所需的那部分JDK模块，而非是整个JDK框架了。
集合工厂方法增强-如集合的不可修改视图的创建。
钻石操作符允许在匿名类上使用。
支持HTTP2和WebSocket协议的API。
HTML5风格的Java帮助文档。

906.如何让系统的服务端主动能推送新消息给客户端浏览器？
采用ajax轮询、http长轮询、comet或websocket技术。

907.微信红包怎么实现的（如群里有人发了一个N人的红包，总金额为M）？秒杀系统的设计思路？
①一、发红包后台操作：
在db（sharding）中增加一条红包记录(含字段：红包总金额、红包总个数、剩余红包个数、剩余红包金额；同时扣减发红包人的钱)，并设置过期时间；
在分布式Cache中增加一条记录，存储抢红包的人数N和总额M。
二、抢红包后台操作：
抢红包分为抢和拆，抢操作在Cache层完成，通过原子减操作（带版本号的CAS，冲突的用户放行进行拆操作）进行红包数递减，到0就说明抢光了，最终实际进入后台拆操作的量不大，通过操作的分离将无效请求直接挡在Cache层外面。
拆红包在db完成，通过db事务操作（cas更新红包记录【剩余红包个数、剩余红包金额】、插入领取流水记录），入账为异步操作。拆的时候会实时计算金额（非预分配），其金额为1分到剩余平均值2倍之间随机数，最大的红包为M*2/N（且不会超过M），当拆了红包后会更新剩余金额和个数。
②秒杀系统：https://mp.weixin.qq.com/s/5aMN9SqaWa57rYGgtdAF_A

908.单点登录设计
实现逻辑：通过cookie验证用户的身份，配置拦截器拦截所有请求，当访问站点时，拦截方法中判断客户端是否存在指定cookie以及是否有效，满足条件则跳主页面，否则跳登录页面。当登录并验证成功后定义cookie并写入客户端。只要不同应用都使用同一cookie规约，他们就是相互信任。
同域SSO：系统检测(包括有效期)并解析cookie的key和value（如pub系统会解析获取登录openId），若有效则跳到主页面；否则跳转到登录页，登录页接口检查用户名和密码正确后，将key和value写入cookie。
同父域SSO：如1.x.com和2.x.com，需新增统一校验接口check.x.com；系统1.x.com获取cookie的key和value，并作为参数服务调用check.x.com接口，check.x.com判断cookie是否有效(包括有效期)，1.x.com收到返回若判断有效，则跳到主页面；若无效或者根本获取不到cookie，跳转到check.x.com的登录接口，check.x.com登录接口检查用户名和密码正确后，写入.x.com父域cookie。
完全跨域SSO：如a.com和b.com，需新增统一校验接口x.com；系统a.com获取cookie的key和value，并作为参数服务调用x.com接口，x.com检查cookie的key和value是否有效，若有效则跳到主页面；若无效或根本拿不到cookie则跳转到a.com的登录页，a.com的登录页接口拿到用户名和密码以后，作为参数服务调用x.com的登录接口，x.com判断用户名和密码是否有效。若a.com收到返回若判断有效后，a.com和b.com对应的添加cookie的接口列表给前端，用户在前端页面主动或被动发起a.com和b.com的添加cookie的接口调用，该接口负责将cookie的key和value设置在a.com或b.com自己域名下。

909.海量数据处理
● Hash法：哈希表。用于快速存取、统计某些数据，将大量数据进行分类。例如提取某日访问网站次数最多的IP地址等。
● Bit-map：使用位数组来表示某些元素是否存在。用于海量数据的快速查找、判重、删除等。如从8位电话号码中查找重复号码或统计不同号码的个数（可用多个bit表示一个数）。
● Bloom Filter：位数组+k个hash函数。定义m位初始化都为0的数组，每个函数都可以将元素映射到某一位。判断某个元素是否属于集合时，查看k个位是否全部为1。缺点：若都为1存在错误率、无法删除元素。如检查英文单词是否拼写正确、邮箱过滤垃圾邮件、找出两个各存放50亿条URL的文件中共同的URL。
● 数据库优化法：创建索引、配置缓存、切表分表、数据采样。
● 倒排索引法：正向索引用来存储每个文档的单词的列表，反向索引则是单词指向了包含它的文档。如常见的学术论文的关键词搜索。
● 外排序法：内存不能一次处理待排序的对象，必须把它以文件的形式存放于外存，排序时(归并排序)再把他们一部分一部分地调入内存进行处理。用于大文件的排序以及去重。
● Trie树：前缀树。根节点不包含字符，除根节点外的每一个子节点都包含一个字符。从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。每个节点包含构成单词数量count。用于词频统计、前缀匹配、字符串排序。
● 堆：二叉堆。适用于海量数据求前N大（小顶堆）、前N小（大顶堆）或中位数（双堆）问题。如100w个数中找最大的前100个数。
● 双层桶：分而治之。因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。如5亿个整数中找出不重复的整数的个数（内存装不下）。将数据分离到不同的区域文件，不同的区域在利用bitmap来解决。
● MapReduce法：将数据划分并交给不同的机器去处理，结果归约。

> 面试都是根据应聘者个人简历和工作履历来的，不同的人被问到的问题肯定会不一样，以上内容仅供参考。
